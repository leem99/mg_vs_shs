{
 "metadata": {
  "name": "make_homer_customer_demand"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Make customer level demand inputs for HOMER Energy models #\n",
      "BY: Mitchell Lee"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Import necessary libraries ###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import pandas as pd \n",
      "import numpy as np\n",
      "import string"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Load in dataframe anaylsis tools ###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "run sd_data_stats.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Get customer demand data ###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "SD = pd.read_csv('../demand_data/ug_hourly.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Use a pivot table to make data sortable ###\n",
      "\n",
      ">Output object is a pandas DataFrame with hierarchical column index.\n",
      "\n",
      "> _Hierarchy_\n",
      "\n",
      "> * Data type: watt_hours_delta, max_credit, min_credit\n",
      "> * Site: ug01, ... , ug08\n",
      "> * Circuit: _1, _2, ..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ug = pd.pivot_table(SD, values = ['watt_hours_delta','max_credit','min_credit'], rows = ['time_stamp'],cols = ['site_id','ip_addr'])['2009':'2015']\n",
      "# make index a timestamp \n",
      "ug.index = pd.PeriodIndex(ug.index, freq='h')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Pull out energy data for site of interest ###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "enter_site = 'ug01' # enter site of interest\n",
      "site = ug['watt_hours_delta'][enter_site]\n",
      "\n",
      "enter_site2 = 'ug04' # enter second site of interest\n",
      "site2 = ug['watt_hours_delta'][enter_site2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Basic filtering of UG01 data (To make data HOMER friendly) ##\n",
      "* Isolate data to 8760 hours (1 year) of interest  \n",
      "* In rows where inverter limilations are exceeded, replace values with zero\n",
      "* Replace NaN values with zero\n",
      "* Convert units from Wh to kWh"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Make version of Homer data  that is easy to read in Pandas ####"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# year of interest\n",
      "site = site['2012-09-01':'2013-08-31 23:00:00']\n",
      "\n",
      "# remove data that exceeds inverter limits\n",
      "invert_lim = 750 # 750 W\n",
      "[rows_lost, junk] = np.shape(site[site.sum(axis =1)>= invert_lim])\n",
      "per_rows_lost = rows_lost/8760.\n",
      "site.ix[site.sum(axis=1) >= invert_lim] =  np.nan\n",
      "\n",
      "# remove ug01_3 outliers that are less than 750 W but are much greater than the rest of the data\n",
      "if enter_site == 'ug01':\n",
      "    site[site['192_168_1_203'] >= 40] = np.nan \n",
      "\n",
      "# remove days where Emax is exceeded\n",
      "site_dly = site.resample('D', how = 'sum')\n",
      "site[site_dly>= 750] = np.nan\n",
      "\n",
      "# make a copy of site that is pandas friendly\n",
      "site_pd = site"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Now complete converting site data in to HOMER friendly version ####"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# replace all other NaN values with zero\n",
      "site = site.fillna(value = 0)\n",
      "\n",
      "# converty units from Wh to kWh\n",
      "site = site/1000.\n",
      "\n",
      "# make sum of citcuits timeseries\n",
      "site_sum = site.sum(axis =1)\n",
      "\n",
      "# remove data is beyond inverter limits from sum of circuits \n",
      "site_sum [site_sum >= invert_lim/1000.] = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Write sum of customer data to Homer readable txt file ###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "site_sum_homer = open('../demand_data/' + enter_site +'_sum.txt', 'w')\n",
      "site_sum_homer.write('\\n'.join(map(str,list(site_sum))))\n",
      "site_sum_homer.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Write customer level data to seperate HOMER readable txt files ###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make list of file to write\n",
      "f_names = ['../demand_data/' + enter_site + \"_\"  + string.split(n,'_')[-1][-1:]+'.txt' if n[-2] == '0' else '../demand_data/' + enter_site + \"_\"  + string.split(n,'_')[-1][-2:]+'.txt' for n in list(site.columns) ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# create and write files one by one\n",
      "\n",
      "for ix, f_nam in enumerate(f_names):\n",
      "    f_new = open(f_nam,'w')\n",
      "    f_new.write('\\n'.join(map(str,list(site[site.columns[ix]]))))\n",
      "    f_new.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Basic filtering of UG04 data (To make data HOMER friendly) ##\n",
      "* Because there isn't a full yead of complete data, construct a 8760 hours (1 year) data set  \n",
      "* In rows where inverter limilations are exceeded, replace values with zero\n",
      "* Replace NaN values with zero\n",
      "* Convert units from Wh to kWh"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Make version of Homer data  that is easy to read in Pandas ####"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# year of interest (from roughly this date onwards daily energy consumption is consistant) \n",
      "site2 = site2['2013-01-01':]\n",
      "\n",
      "# remove data that exceeds inverter limits\n",
      "invert_lim = 750 # 750 W\n",
      "[rows_lost, junk] = np.shape(site2[site2.sum(axis =1)>= invert_lim])\n",
      "per_rows_lost = rows_lost/8760.\n",
      "site2.ix[site2.sum(axis=1) >= invert_lim] =  np.nan\n",
      "\n",
      "# remove days where Emax is exceeded\n",
      "site2_dly = site.resample('D', how = 'sum')\n",
      "site2[site2_dly>= 750] = np.nan\n",
      "\n",
      "# make a copy of site that is pandas friendly\n",
      "site2_pd = site2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Remove Circuits without Data ####"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ug04_circuit_list = list(site2_pd.columns)\n",
      "\n",
      "# remove 192_168_1_200 because it is the mains\n",
      "ug04_circuit_list.remove('192_168_1_200')\n",
      "\n",
      "# remove 192_168_1_202 and  192_168_1_210 because there is little to no data for these sites\n",
      "ug04_circuit_list.remove('192_168_1_202')\n",
      "ug04_circuit_list.remove('192_168_1_210')\n",
      "\n",
      "site2_pd = site2_pd[ug04_circuit_list]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Remove dates with out any data to get rid of the big gap in the middle of the data set ####"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# aggrigate site2 into daily resolution to find full days without data\n",
      "site2_pd_dly = site2_pd.resample('D', how = 'sum').sum(axis=1).dropna()\n",
      "\n",
      "#find first hour of all days without data\n",
      "nuker = pd.DataFrame(site2_pd_dly.resample('h'), columns = ['nuker'])\n",
      "\n",
      "#fill all other hours of days without data\n",
      "nuker = nuker.fillna(method='ffill',limit = 23).dropna()\n",
      "\n",
      "# remove all hours of days without data from site2_pd\n",
      "site2_pd = site2_pd.join(nuker,how='right')\n",
      "\n",
      "#delete nuker column\n",
      "del site2_pd['nuker']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Make 8760 hour data set of UG04 data ####"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Turn UG04 dataframe into a numpy array with all NaN filled as zero \n",
      "site2_ary =  np.array(site2_pd.fillna(0))\n",
      "\n",
      "# Keep appending to site2_pd until it is more than 8760 hours long  \n",
      "rows = np.shape(site2_ary)[0]\n",
      "\n",
      "while rows <= 8760:\n",
      "    site2_ary = np.append(site2_ary,site2_ary,axis = 0)\n",
      "    rows = np.shape(site2_ary)[0]\n",
      "    \n",
      "site2_ary = site2_ary[0:8760,:]\n",
      "\n",
      "# convert back into pandas dataframe\n",
      "site2_composite_year = pd.DataFrame(site2_ary, columns = site2_pd.columns)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Now complete converting site data in to HOMER friendly version ####"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make sum of citcuits timeseries\n",
      "site2_composite_year_sum = site2_composite_year.sum(axis = 1)\n",
      "\n",
      "# converty units from Wh to kWh\n",
      "site2_composite_year = site2_composite_year/1000\n",
      "site2_composite_year_sum = site2_composite_year_sum/1000\n",
      "\n",
      "# make sum of citcuits timeseries\n",
      "site2_composite_year_sum = site2_composite_year.sum(axis =1)\n",
      "\n",
      "# remove data is beyond inverter limits from sum of circuits \n",
      "site2_composite_year[site2_composite_year_sum >= invert_lim/1000.] = 0\n",
      "\n",
      "# remove data is beyond inverter limits from sum of circuits \n",
      "site2_composite_year_sum[site2_composite_year_sum >= invert_lim/1000.] = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Write sum of customer data to Homer readable txt file ###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "site_sum_homer = open('../demand_data/' + enter_site2 +'_sum.txt', 'w')\n",
      "site_sum_homer.write('\\n'.join(map(str,list(site2_composite_year_sum ))))\n",
      "site_sum_homer.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Write customer level data to seperate HOMER readable txt files ###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make list of file to write\n",
      "f_names = ['../demand_data/' + enter_site2 + \"_\"  + string.split(n,'_')[-1][-1:]+'.txt' if n[-2] == '0' else '../demand_data/' + enter_site2 + \"_\"  + string.split(n,'_')[-1][-2:]+'.txt' for n in list(site2_composite_year.columns) ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# create and write files one by one\n",
      "\n",
      "for ix, f_nam in enumerate(f_names):\n",
      "    f_new = open(f_nam,'w')\n",
      "    f_new.write('\\n'.join(map(str,list(site2_composite_year[site2_composite_year.columns[ix]]))))\n",
      "    f_new.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = site2_pd\n",
      "x = x.fillna(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    }
   ],
   "metadata": {}
  }
 ]
}