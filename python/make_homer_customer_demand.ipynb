{
 "metadata": {
  "name": "make_homer_customer_demand"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Make customer level demand inputs for HOMER Energy models #\n",
      "BY: Mitchell Lee"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Import necessary libraries ###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import pandas as pd \n",
      "import numpy as np\n",
      "import string"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Load in dataframe anaylsis tools ###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "run sd_data_stats.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Get customer demand data ###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "SD = pd.read_csv('../demand_data/ug_hourly.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Use a pivot table to make data sortable ###\n",
      "\n",
      ">Output object is a pandas DataFrame with hierarchical column index.\n",
      "\n",
      "> _Hierarchy_\n",
      "\n",
      "> * Data type: watt_hours_delta, max_credit, min_credit\n",
      "> * Site: ug01, ... , ug08\n",
      "> * Circuit: _1, _2, ..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ug = pd.pivot_table(SD, values = ['watt_hours_delta','max_credit','min_credit'], rows = ['time_stamp'],cols = ['site_id','ip_addr'])\n",
      "# make index a timestamp \n",
      "ug.index = pd.PeriodIndex(ug.index, freq='h')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Pull out energy data for site of interest ###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "enter_site = 'ug01' # enter site of interest\n",
      "site = ug['watt_hours_delta'][enter_site]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Basic filtering of UG01 data (To make data HOMER friendly) ###\n",
      "* Isolate data to 8760 hours (1 year) of interest  \n",
      "* In rows where inverter limilations are exceeded, replace values with zero\n",
      "* Replace NaN values with zero\n",
      "* Convert units from Wh to kWh"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# year of interest\n",
      "site = site['2012-09-01':'2013-08-31']\n",
      "\n",
      "# remove data that exceeds inverter limits\n",
      "invert_lim = 750 # 750 W\n",
      "[rows_lost, junk] = np.shape(site[site.sum(axis =1)>= invert_lim])\n",
      "per_rows_lost = rows_lost/8760.\n",
      "site.ix[site.sum(axis=1) >= invert_lim] =  0\n",
      "\n",
      "# remove days where Emax is exceeded\n",
      "site_dly = site.resample('D', how = 'sum')\n",
      "\n",
      "# replace all other NaN values with zero\n",
      "site = site.fillna(value = 0)\n",
      "\n",
      "# converty units from Wh to kWh\n",
      "site = site/1000.\n",
      "\n",
      "# make sum of citcuits timeseries\n",
      "site_sum = site.sum(axis =1)\n",
      "\n",
      "# remove data is beyond inverter limits from sum of circuits \n",
      "site_sum [site_sum >= invert_lim/1000] = 0\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Write sum of customer data to Homer readable txt file ###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "site_sum_homer = open('../demand_data/' + enter_site +'_sum.txt', 'w')\n",
      "site_sum_homer.write('\\n'.join(map(str,list(site_sum))))\n",
      "site_sum_homer.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Write customer level data to seperate HOMER readable txt files ###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make list of file to write\n",
      "f_names = ['../demand_data/' + enter_site + \"_\"  + string.split(n,'_')[-1][-1:]+'.txt' if n[-2] == '0' else '../demand_data/' + enter_site + \"_\"  + string.split(n,'_')[-1][-2:]+'.txt' for n in list(site.columns) ]\n",
      "f_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 84,
       "text": [
        "['../demand_data/ug01_0.txt',\n",
        " '../demand_data/ug01_1.txt',\n",
        " '../demand_data/ug01_2.txt',\n",
        " '../demand_data/ug01_3.txt',\n",
        " '../demand_data/ug01_4.txt',\n",
        " '../demand_data/ug01_5.txt',\n",
        " '../demand_data/ug01_6.txt',\n",
        " '../demand_data/ug01_7.txt',\n",
        " '../demand_data/ug01_8.txt',\n",
        " '../demand_data/ug01_9.txt',\n",
        " '../demand_data/ug01_10.txt']"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "\n",
      "# create and write files one by one\n",
      "\n",
      "for ix, f_nam in enumerate(f_names):\n",
      "    f_new = open(f_nam,'w')\n",
      "    f_new.write('\\n'.join(map(str,list(site[site.columns[ix]]))))\n",
      "    f_new.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}